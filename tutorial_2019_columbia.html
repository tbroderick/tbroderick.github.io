<html>

<head>
<meta http-equiv="content-type" content="text/html; charset=iso-8859-1"/>
<meta name="description" content="Variational Bayes and beyond: Bayesian inference for big data"/>
<meta name="keywords" content="Variational,Bayes,Tutorial"/>
<meta name="author" content="Tamara Broderick"/>
<title>QUT 2019 Variational Bayes Tutorial</title>
</head>

<body class="course-page">
<h1>Tutorial "Variational Bayes and Beyond: Foundations of Scalable Bayesian Inference"</h1>

This tutorial is part of the <a href="http://statisticalml.stat.columbia.edu/event/sampling-variational-inference-and-related-topics/">Tutorials on Sampling and Variational Inference</a> during the Special Year on Statistical Machine Learning at Columbia University in the City of New York. The tutorial is taking place at Davis Auditorium at 530 West 120th Street in New York, NY, USA.
See <a href="http://www.tamarabroderick.com/tutorials.html">this link</a> for other tutorials.

<p>
<b>Instructor</b>:
<br>&nbsp; Professor <a href="http://www.tamarabroderick.com">Tamara Broderick</a>
<br>&nbsp; Email: <img src="img/broderick_email.png" height=16em style="position: relative; top: 1.5px;">
</p>

<hr>

<h2>Materials and Description</h2>

<p>
<ul>
<li><a href="files/broderick_tutorial_2019_columbia.pdf">[Full Slides]</a>
</li>
</ul>

<p><b>Title</b>: Variational Bayes and Beyond: Foundations of Scalable Bayesian Inference

<p>
<b>Abstract</b>:
Bayesian methods exhibit a number of desirable
properties for modern data analysis---including (1) coherent
quantification of uncertainty, (2) a modular modeling framework able
to capture complex phenomena, (3) the ability to incorporate prior
information from an expert source, and (4) interpretability. In
practice, though, Bayesian inference necessitates approximation of a
high-dimensional integral, and some traditional algorithms for this
purpose can be slow---notably at data scales of current interest. The
tutorial will cover the foundations of some modern tools for fast,
approximate Bayesian inference at scale. One increasingly popular
framework is provided by "variational Bayes" (VB), which formulates
Bayesian inference as an optimization problem. We will examine key
benefits and pitfalls of using VB in practice, with a focus on the
widespread "mean-field variational Bayes" (MFVB) subtype. We will
highlight properties that anyone working with VB, from the data
analyst to the theoretician, should be aware of. And we will discuss a
number of open challenges.

<h2>Prerequisites</h2>

Basic familiarity with Bayesian data analysis and its goals. Be familiar with the following concepts: priors, likelihoods, posteriors, Bayes Theorem,
and conjugacy (for discrete and continuous distributions).

</body>

</html>
